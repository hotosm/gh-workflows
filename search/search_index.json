{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"HOT Github Workflows","text":"<p> Github workflows that can be shared across all HOT projects. </p> <p> </p> <p>\ud83d\udcd6 Documentation: https://hotosm.github.io/gh-workflows</p> <p>\ud83d\udda5\ufe0f Source Code: https://github.com/hotosm/gh-workflows</p>"},{"location":"#intro","title":"Intro","text":"<p>\u2699\ufe0f Intro to Workflows</p> <p>This repo contains reusable workflows, that can be called from any other repo.</p> <p>Motivations for creating this:</p> <ul> <li>Reduce code duplication for workflows across our repos.</li> <li>Easy version control and upgrading of our workflows over time.</li> <li>Attempt to find the best possible implementation of the workflow,   then standardise across repos.</li> </ul>"},{"location":"#to-add-new-workflows","title":"To add new workflows","text":"<ul> <li>Add your <code>.yml</code> workflow to <code>.github/workflows</code>.</li> <li>Create a <code>.md</code> file under <code>docs</code>, in the same format as the others.<ul> <li>The file should have empty content, with a title,   and ## headers: Inputs, Outputs, Secrets.</li> </ul> </li> <li>Add to <code>.github/workflows/workflow_docs.yml</code>:<ul> <li>A step in the same format as others using <code>tj-actions/auto-doc@v3</code>,   changing variables.</li> <li>Add an entry under <code>files</code> in the Verify Changed Files step.</li> </ul> </li> <li>Add an entry to <code>mkdocs.yml</code> nav section.</li> </ul>"},{"location":"#to-manually-document-workflows-using-auto-doc","title":"To manually document workflows using auto-doc","text":"<p>Replace the .yml and .md file names below:</p> <pre><code>curl -LO https://github.com/tj-actions/auto-doc/releases/download/v3.1.0/auto-doc_3.1.0_Linux_x86_64.tar.gz\n\ntar -xzsf auto-doc_3.1.0_Linux_x86_64.tar.gz\n\nrm -rf auto-doc_3.1.0_Linux_x86_64.tar.gz\n\n./auto-doc --filename .github/workflows/openapi_build.yml \\\n    --output docs/openapi_build.md --reusable\n\nrm auto-doc\n</code></pre>"},{"location":"doxygen_build/","title":"Doxygen Build","text":"<p>This workflow is used to build a Doxygen class hierarchy.</p> <p>It needs a Doxyfile present under <code>docs/Doxyfile</code>.</p>"},{"location":"doxygen_build/#inputs","title":"Inputs","text":"INPUT TYPE REQUIRED DEFAULT DESCRIPTION output_path string false If specified, the output dir is uploaded named <code>artifact</code>."},{"location":"doxygen_build/#outputs","title":"Outputs","text":"OUTPUT VALUE DESCRIPTION artifact_name <code>\"doxygen\"</code> The artifact name (default: <code>artifact</code>)."},{"location":"doxygen_build/#secrets","title":"Secrets","text":"<p>No secrets.</p>"},{"location":"doxygen_build/#example-usage","title":"Example Usage","text":"<pre><code>name: \ud83d\udcd6 Publish Docs\n\non:\n  push:\n    paths:\n      - docs/**\n      - src/**\n      - mkdocs.yml\n    branches: [development]\n  # Allow manual trigger (workflow_dispatch)\n  workflow_dispatch:\n\njobs:\n  build_doxygen:\n    uses: hotosm/gh-workflows/.github/workflows/doxygen_build.yml@1.6.0\n    with:\n      output_path: docs/apidocs\n\n  publish_docs:\n    uses: hotosm/gh-workflows/.github/workflows/mkdocs_build.yml@1.6.0\n    needs:\n      - build_doxygen\n    with:\n      image: ghcr.io/${{ github.repository }}/backend:ci-${{ github.ref_name }}\n      doxygen: true\n</code></pre>"},{"location":"env_vars/","title":"Extract Env Vars","text":"<p>THIS WORKFLOW IS CURRENTLY NON-FUNCTIONAL</p>"},{"location":"env_vars/#inputs","title":"Inputs","text":"INPUT TYPE REQUIRED DEFAULT DESCRIPTION environment string true The Github environment to retreive the env and secret var for."},{"location":"env_vars/#outputs","title":"Outputs","text":"OUTPUT VALUE DESCRIPTION all_vars <code>\"${{ jobs.get_env_vars.outputs.all_vars }}\"</code> All parsed variables and secrets."},{"location":"env_vars/#secrets","title":"Secrets","text":"<p>No secrets.</p>"},{"location":"env_vars/#example-usage","title":"Example Usage","text":"<pre><code>get-env-vars:\n  uses: hotosm/gh-workflows/.github/workflows/env_vars.yml@1.6.0\n  with:\n    environment: ${{ github.ref_name }}\n\nfrontend-build:\n  uses: hotosm/gh-workflows/.github/workflows/image_build.yml@1.6.0\n  needs:\n    - frontend-tests\n    - get-env-vars\n  with:\n    context: src/frontend\n    dockerfile: prod.dockerfile\n    build_target: prod\n    image_name: ghcr.io/${{ github.repository }}/frontend\n    extra_build_args: |\n      VITE_API_URL=${{ needs.get-env-vars.outputs.all_vars }}\n</code></pre>"},{"location":"image_artifact/","title":"Container Image Artifact","text":"<p>This workflow is used to upload container images as artifacts during a workflow.</p> <p>This is useful for 'caching' an downloaded image, if it if used again within the same workflow, preventing repeated pulls.</p> <p>This may or may not be faster than pulling the image again, as the image still has to pull from thr artifact API.</p> <p>However, it does prevent repeated pull from container registries where rate limiting is applied (e.g. dockerhub).</p> <p>Note: this strategy does not work across workflow runs.</p>"},{"location":"image_artifact/#inputs","title":"Inputs","text":"INPUT TYPE REQUIRED DEFAULT DESCRIPTION image_names string true A space separated list of full image names to upload, including tag."},{"location":"image_artifact/#outputs","title":"Outputs","text":"OUTPUT VALUE DESCRIPTION artifact_name <code>\"images\"</code> The artifact name (default: <code>artifact</code>)."},{"location":"image_artifact/#secrets","title":"Secrets","text":"<p>No secrets.</p>"},{"location":"image_artifact/#example-usage","title":"Example Usage","text":"<p>In this example, we cache various dependent images, to prevent download every time pytest is run.</p> <pre><code>jobs:\n  artifact-imgs:\n    uses: hotosm/gh-workflows/.github/workflows/image_artifact.yml@main\n    with:\n      image_names: |\n        docker.io/postgis/postgis:${{ vars.POSTGIS_TAG }}\n        ghcr.io/hotosm/field-tm/odkcentral:${{ vars.ODK_CENTRAL_TAG }}\n        docker.io/minio/minio:${{ vars.MINIO_TAG }}\n\n  run-pytest:\n    runs-on: ubuntu-latest\n    needs: [artifact-imgs]\n    environment:\n      name: ${{ inputs.environment || 'test' }}\n\n    steps:\n      - name: Checkout repository\n        uses: actions/checkout@v4\n\n      - name: Download Images Tars\n        id: download-images\n        uses: actions/download-artifact@v4\n        with:\n          path: /tmp/images\n\n      - name: Load Tar Imgs\n        run: |\n          for image_tar in /tmp/images/*; do\n              docker image load --input $image_tar || true\n          done\n\n      - name: Run PyTest\n        run: |\n          docker compose run api \\\n            wait-for-it fmtm-db:5432 --strict \\\n            -- wait-for-it central:8383 --strict --timeout=30 \\\n            -- pytest\n</code></pre>"},{"location":"image_build/","title":"Container Image Build","text":"<p>This workflow is used to build container images in a standardised way.</p>"},{"location":"image_build/#usage","title":"Usage","text":"<p>Basic usage of this action only requires the image_name input.</p> <pre><code>test-img-build:\n  uses: hotosm/gh-workflows/.github/workflows/image_build.yml@1.6.0\n  with:\n    image_name: ghcr.io/${{ github.repository }}\n</code></pre> <p>This will build an image for the repository.</p> <p>If multiple images are built in the same repository, it is possible to name the images under separate paths:</p> <pre><code>ghcr.io/${{ github.repository }}/backend\nghcr.io/${{ github.repository }}/frontend\nghcr.io/${{ github.repository }}/some-other-service\n</code></pre>"},{"location":"image_build/#defaults","title":"Defaults","text":"<ul> <li>Build an image using the root directory, and file <code>Dockerfile</code>.</li> <li>Automatically tag your image, depending on the branch or   version number.</li> <li>Inject the build-args:<ul> <li>APP_VERSION=${{ github.ref_name }} (the current branch or tag)</li> <li>COMMIT_REF=${{ github.sha }} (the current commit)</li> </ul> </li> <li>Cache your image in the Github Container Registry for future builds.</li> <li>Push your image to the registry for future use.</li> </ul>"},{"location":"image_build/#vulnerability-scanning","title":"Vulnerability Scanning","text":"<p>Two types of vulnerability scan are available.</p> <p>Both are enabled by default.</p>"},{"location":"image_build/#static-code-analysis-of-dockerfile","title":"Static Code Analysis of Dockerfile","text":"<p>Scanning of Dockerfiles for best practice security is done by checkov.</p> <p>This can be disabled with the input parameter: <code>scan_dockerfile: false</code>.</p>"},{"location":"image_build/#cve-scanning-of-built-image","title":"CVE Scanning of Built Image","text":"<p>The built image is scanned for CVEs present in the installed software by Trivy.</p> <p>This can be disabled with the input parameter: <code>scan_image: false</code>.</p>"},{"location":"image_build/#multi-architecture-builds","title":"Multi Architecture Builds","text":"<p>There is basic support for building multi-architecture images.</p> <p>By using the <code>multi_arch: true</code> option, builds can be made for AMD64 (default Linux/Windows), and ARM64 (newer MacOS M-chips).</p> <p>Please note, however, that using <code>multi_arch</code> may increase your build time by up to 3x.</p> <p>If speed is important, there is another workflow availble named image_build_multi that will build across multiple Github runners and should be faster (amd64 | arm/v6 | arm/v7 | arm64).</p> <p>Note: you should carefully consider if multi-architecture builds are worth the performance tradeoff.</p> <p>As of 2023, deployment on architectures other than AMD64 is rare. To accomodate MacOS users during app development, it is suggested they build the image themselves on their own architecture (often a single command).</p>"},{"location":"image_build/#inputs","title":"Inputs","text":"INPUT TYPE REQUIRED DEFAULT DESCRIPTION build_target string false The target to built to (default to end of the Dockerfile). cache boolean false <code>true</code> Use GHCR caching. Default true. Set this false if registry is not ghcr.io. context string false <code>\".\"</code> Root directory to start the build from. dockerfile string false <code>\"Dockerfile\"</code> Name of dockerfile, relative to context dir. environment string false <code>\"${{ github.ref_name }}\"</code> The environment to use for variables. extra_build_args string false Space separated list of extra build args to use for the image. image_name string false Name of image, without tags. Not required if image_tags specified. image_tags string false Default=the images are automatically tagged. Override tags with space separated list. multi_arch boolean false <code>false</code> Build a multi-arch image for AMD64/ARM64. push boolean false <code>true</code> Override prevent pushing the image. registry string false <code>\"ghcr.io\"</code> Override GHCR to use an external reg. scan_dockerfile boolean false <code>true</code> Enable dockerfile vulnerability scanning, prior to build. scan_image boolean false <code>true</code> Enable image vulnerability scan, after build. skip_cve string false <code>\"CKV_DOCKER_8,CKV_DOCKER_2,CKV_DOCKER_3,CKV_DOCKER_5\"</code> Skip specific CVE from checkcov (override rules)."},{"location":"image_build/#outputs","title":"Outputs","text":"OUTPUT VALUE DESCRIPTION image_name <code>\"${{ jobs.build-image.outputs.image_name }}\"</code> The final full image reference. image_tag <code>\"${{ jobs.build-image.outputs.image_tag }}\"</code> The final image tag."},{"location":"image_build/#secrets","title":"Secrets","text":"<p>No secrets.</p>"},{"location":"image_build/#example-usage","title":"Example Usage","text":"<p>Standalone</p> <p>Multi-arch, cached, auto-tag, auto-push:</p> <pre><code>backend-build:\n  uses: hotosm/gh-workflows/.github/workflows/image_build.yml@main\n  with:\n    context: src/backend\n    build_target: prod\n    image_name: ghcr.io/${{ github.repository }}/backend\n    extra_build_args: |\n      APP_VERSION=${{ github.ref_name }}\n      COMMIT_REF=${{ github.sha }}\n</code></pre> <p>Manual tagging:</p> <pre><code>backend-build:\n  uses: hotosm/gh-workflows/.github/workflows/image_build.yml\n  with:\n    context: src/backend\n    build_target: prod\n    image_tags: |\n      \"ghcr.io/hotosm/field-tm/backend:latest\"\n    extra_build_args: |\n      APP_VERSION=0.1.0\n</code></pre> <p>Passing Variables</p> <p>Example variable extraction from FieldTM:</p> <pre><code>name: Extract Project Variables\n\non:\n  workflow_call:\n    inputs:\n      environment:\n        description: \"The GitHub environment to extract vars from.\"\n        type: string\n        default: \"\"\n    outputs:\n      api_version:\n        description: \"Backend API Version.\"\n        value: ${{ jobs.extract-vars.outputs.api_version }}\n\njobs:\n  extract-vars:\n    runs-on: ubuntu-latest\n    environment: ${{ inputs.environment }}\n    outputs:\n      api_version: ${{ steps.extract_api_version.outputs.api_version }}\n\n    steps:\n      - name: Checkout repository\n        uses: actions/checkout@v4\n\n      - name: Extract api version\n        id: extract_api_version\n        run: |\n          cd src/backend\n          API_VERSION=$(python -c 'from app.__version__ import __version__; print(__version__)')\n          echo \"api_version=${API_VERSION}\" &gt;&gt; $GITHUB_OUTPUT\n</code></pre> <p>Then example variable passing from FieldTM:</p> <pre><code>jobs:\n  extract-vars:\n    needs:\n      - pytest\n      - frontend-tests\n    uses: ./.github/workflows/extract_vars.yml\n    with:\n      environment: ${{ github.ref_name }}\n\n  backend-build:\n    uses: hotosm/gh-workflows/.github/workflows/image_build.yml\n    needs: extract-vars\n    with:\n      context: src/backend\n      build_target: prod\n      image_tags: |\n        \"ghcr.io/hotosm/field-tm/backend:${{ needs.extract-vars.outputs.api_version }}-${{ github.ref_name }}\"\n        \"ghcr.io/hotosm/field-tm/backend:latest\"\n      extra_build_args: |\n        APP_VERSION=${{ needs.extract-vars.outputs.api_version }}\n</code></pre>"},{"location":"image_build_multi/","title":"Multi-Architecture Image Build","text":"<p>This workflow is used to build container images that are compatible with multiple architectures.</p> <p>Supports:</p> <ul> <li>linux/amd64</li> <li>linux/arm/v6</li> <li>linux/arm/v7</li> <li>linux/arm64</li> </ul>"},{"location":"image_build_multi/#inputs","title":"Inputs","text":"INPUT TYPE REQUIRED DEFAULT DESCRIPTION build_target string false The target to built to (default to end of the Dockerfile). cache boolean false <code>true</code> Use GHCR caching. Default true. Set this false if registry is not ghcr.io. context string false <code>\".\"</code> Root directory to start the build from. dockerfile string false <code>\"Dockerfile\"</code> Name of dockerfile, relative to context dir. environment string false <code>\"${{ github.ref_name }}\"</code> The environment to use for variables. extra_build_args string false Space separated list of extra build args to use for the image. image_name string false Name of image, without tags. Not required if image_tags specified. image_tags string false Default=the images are automatically tagged. Override tags with space separated list. push boolean false <code>true</code> Override prevent pushing the image. registry string false <code>\"ghcr.io\"</code> Override GHCR to use an external reg. scan_dockerfile boolean false <code>true</code> Enable dockerfile vulnerability scanning, prior to build. scan_image boolean false <code>true</code> Enable image vulnerability scan, after build. skip_cve string false <code>\"CKV_DOCKER_8,CKV_DOCKER_2,CKV_DOCKER_3,CKV_DOCKER_5\"</code> Skip specific CVE from checkcov (override rules)."},{"location":"image_build_multi/#secrets","title":"Secrets","text":"<p>No secrets.</p>"},{"location":"image_build_multi/#outputs","title":"Outputs","text":"OUTPUT VALUE DESCRIPTION image_name <code>\"${{ jobs.build-images.outputs.image_name }}\"</code> The final full image reference. image_tag <code>\"${{ jobs.build-images.outputs.image_tag }}\"</code> The final image tag."},{"location":"image_build_multi/#example-usage","title":"Example Usage","text":"<pre><code>test-img-build:\nuses: hotosm/gh-workflows/.github/workflows/image_build_multi.yml@1.3.3\nwith:\n  image_name: ghcr.io/${{ github.repository }}\n</code></pre>"},{"location":"intro/","title":"Github Workflows Intro","text":"<ul> <li>Github workflows are for CI/CD in Github, similar to Gitlab pipelines.</li> </ul> <ul> <li>The name for the platform as a whole is Github Actions (although   they are used quite interchangably).</li> </ul> <ul> <li>There is similar external CI/CD software (e.g. CircleCI), but   having workflows close to the code is helpful for better integration.</li> </ul> <ul> <li>At HOT we also use Github Container Registry to store container images.</li> </ul>"},{"location":"intro/#concepts","title":"Concepts","text":"<p>There is comprehensive official documentation of Github Actions / Workflows.</p> <p>Important Info:</p> <ul> <li> <p>There are 3 levels of jobs: steps --&gt; jobs --&gt; workflows.</p> <ul> <li>A step is the lowest level, typically running the actual code   in a bash shell.</li> <li>A job encapsulates many steps, to have an end outcome.</li> <li>A workflow encapsulates many jobs.</li> </ul> </li> </ul> <ul> <li>Each job in a workflow run on a seperate machine (runner),   with different packages, containers, cache, etc.</li> </ul> <ul> <li>Typically workflows run on the <code>ubuntu-latest</code> image. Unless   something simple, it is generally better practice to run your   job inside a specifc container (for consistency).</li> </ul>"},{"location":"intro/#types","title":"Types","text":""},{"location":"intro/#local-repo-workflows","title":"Local Repo Workflows","text":"<ul> <li>Located under <code>.github/workflows/workflow_name.yml</code>.</li> <li>Specific to your repo. Run on based on set criteria.</li> </ul>"},{"location":"intro/#reusable-local-workflows","title":"Reusable Local Workflows","text":"<ul> <li>Also located under <code>.github/workflows/workflow_name.yml</code>.</li> <li>Use the <code>workflow_call</code> trigger, meaning they can only be called   from another parent workflow.</li> <li>Useful if you repeat the same job multiple times, i.e. DRY code.</li> </ul>"},{"location":"intro/#reusable-remote-workflows","title":"Reusable Remote Workflows","text":"<ul> <li>Located under <code>.github/workflows/workflow_name.yml</code>, but within   another Git repository.</li> <li>A centralised location can be used to store workflows to be called   from other repos.</li> <li>Exactly what this repo is!</li> </ul>"},{"location":"intro/#github-actions","title":"Github Actions","text":"<ul> <li>A single workflow job packaged up for use / calling from within   another workflow.</li> <li>There is a lot of overlap here with reusable workflows - they operate   in a very similar way.</li> <li>The file structure is defined slightly differently, but the important   thing to note is that a single job is defined per published repo.</li> <li>HOT does not maintain any Actions as of now, but we use plenty of   official and unofficial Actions within our workflows.</li> </ul>"},{"location":"intro/#triggers","title":"Triggers","text":"<p>There are quite a few triggers. The main ones to note are below.</p>"},{"location":"intro/#push","title":"push","text":"<ul> <li>A standard push to the repo.</li> <li>Useful for deployment &amp; publishing workflows.</li> <li>Workflow runs on the branch you merged into (e,g. main, development).</li> <li>Can specify which branch, or which files to trigger on.</li> <li>Also covers when a PR is merged (this is essentially a push too).</li> <li>Includes tag pushes.</li> </ul>"},{"location":"intro/#pull_request","title":"pull_request","text":"<ul> <li>Runs when a PR is made.</li> <li>Useful for testing workflows.</li> <li>Runs on the PR source branch (i.e. the one you want to merge).</li> </ul>"},{"location":"intro/#pull_request_target","title":"pull_request_target","text":"<ul> <li>Runs when a PR is made, BUT runs on the target branch instead.</li> <li>For <code>feat/some-feat</code> --&gt; <code>main</code>, then would be the <code>main</code> branch.</li> <li>Give's some extra permissions to the workflow, so use with caution.</li> <li>We only use this for the PR Label workflow, as it allows for labelling   of the PR, even if the PR author does not have repo permissions.</li> </ul>"},{"location":"intro/#workflow_call","title":"workflow_call","text":"<ul> <li>Runs when called from another workflow.</li> <li>What we use mostly throughout this repo, to make 'reusable' workflows.</li> </ul>"},{"location":"intro/#using-reusable-workflows","title":"Using Reusable Workflows","text":"<p>You need two keys to run a reusable workflow: <code>uses</code> and <code>with</code>.</p> <p>Example:</p> <pre><code>frontend-build:\n  uses: hotosm/gh-workflows/.github/workflows/image_build.yml@main\n  needs: [frontend-tests]\n  with:\n    context: src/frontend\n    dockerfile: prod.dockerfile\n    build_target: prod\n    image_name: ghcr.io/${{ github.repository }}/frontend\n    extra_build_args: |\n      APP_VERSION=${{ github.ref_name }}\n      COMMIT_REF=${{ github.sha }}\n      VITE_API_URL=${{ vars.URL_SCHEME }}://${{ vars.API_URL }}\"\n</code></pre> <p>As you can see, <code>uses</code> is to define the workflow you want to run:</p> <p>The version of the workflow can be specified after the <code>@</code> symbol. It is bad practic to use @main. Generally you should release tagged versions of the reusable workflows, then specify the tag, e.g. @0.1.2</p> <p>The <code>with</code> key is used to specify all of the inputs to pass to the workflow. (these are predefined by the creator of the reusable workflow).</p>"},{"location":"intro/#using-secrets-in-reusable-workflows","title":"Using Secrets in Reusable Workflows","text":"<p>By default reusable workflows will not have access to environment secrets, unless specified in the workflow definition.</p> <p>There are two ways to do this:</p> <ol> <li> <p>Specify secrets individually:</p> <pre><code>jobs:\n  pytest:\n    uses: hotosm/gh-workflows/.github/workflows/some_workflow.yml@main\n    secrets:\n      SECRET_VAR_1: ${{ secrets.SECRET_VAR_1 }}\n      SECRET_VAR_2: ${{ secrets.SECRET_VAR_2 }}\n</code></pre> </li> <li> <p>Inherit all secrets (recommended):</p> <pre><code>jobs:\n  pytest:\n    uses: hotosm/gh-workflows/.github/workflows/some_workflow.yml@main\n    secrets: inherit\n</code></pre> </li> </ol>"},{"location":"intro/#passing-info-between-workflows","title":"Passing Info Between Workflows","text":"<p>As noted above, each reusable workflow runs on a different machine (runner).</p> <p>There are various ways to pass information between different workflow jobs.</p>"},{"location":"intro/#environment-variables","title":"Environment Variables","text":"<p>Any variable in $GITHUB_ENV will be available to all jobs in the workflow.</p> <p>Set a variable:</p> <pre><code>echo \"README_PATH=./README.md\" &gt;&gt; $GITHUB_ENV\n</code></pre> <p>Read a variable:</p> <pre><code># Read the content of the file\ncat $README_PATH\n# Alternative syntax\ncat ${{ env.README_PATH }}\n</code></pre>"},{"location":"intro/#outputs","title":"Outputs","text":"<p>Outputs can be defined on a step level, job level, and workflow level.</p>"},{"location":"intro/#step-output","title":"Step Output","text":"<p>Typically the output is defined by code within a step:</p> <pre><code># ... some code to determine var_content\necho \"var1=${var_content}\" &gt;&gt; $GITHUB_OUTPUT\n</code></pre> <p>This can be read in another step (using the step id):</p> <pre><code>steps:\n  - id: first-task\n    name: Set the var\n    run: |\n      echo \"var1=${var_content}\" &gt;&gt; $GITHUB_OUTPUT\n\n  - name: Read the var\n    run: |\n      echo ${{ steps.first-task.outputs.var1 }}\n</code></pre>"},{"location":"intro/#job-output","title":"Job Output","text":"<p>Outputs defined in a step can be set a job outputs, making them available to other jobs in the workflow.</p> <pre><code>jobs:\n  build-image:\n    runs-on: ubuntu-latest\n\n    outputs:\n      image_name: ${{ steps.get_image_name.outputs.image_name }}\n      image_tag: ${{ steps.get_image_name.outputs.image_tag }}\n</code></pre> <p>This can be read by another job in the workflow:</p> <p>To use the output from a workflow, we have to use the <code>needs</code> keyword to create a linking between two jobs.</p> <pre><code>jobs:\n  job1:\n    runs-on: ubuntu-latest\n\n    outputs:\n      var1: ${{ steps.first-task.outputs.var1 }}\n\n    steps:\n      - id: first-task\n        name: Set the var\n        run: |\n          echo \"var1=${var_content}\" &gt;&gt; $GITHUB_OUTPUT\n\n  job2:\n    runs-on: ubuntu-latest\n    needs: [job1]\n\n    steps:\n      - name: Get the var\n        run: |\n          echo \"${{ needs.job1.outputs.var1 }}\"\n</code></pre>"},{"location":"intro/#workflow-output","title":"Workflow Output","text":"<ul> <li>Outputs can also be passed up to the workflow level.</li> <li>This is especially useful for reusable workflows.</li> <li>We can define an standard output for the workflow, then   pass the value onto our next called workflow.</li> </ul> <p>As with passing data between jobs, we also have to use the <code>needs</code> keyword to pass data between workflows.</p> <pre><code># some_workflow.yml\n\non:\n  workflow_call:\n    outputs:\n      var1:\n        description: \"The test var.\"\n        value: ${{ jobs.job1.outputs.var1 }}\n\njobs:\n  job1:\n    runs-on: ubuntu-latest\n\n    outputs:\n      var1: ${{ steps.first-task.outputs.var1 }}\n\n    steps:\n      - id: first-task\n      name: Set the var\n      run: |\n          echo \"var1=${var_content}\" &gt;&gt; $GITHUB_OUTPUT\n</code></pre> <p>We can then use this in our parent workflow:</p> <pre><code>do-something:\n  uses: hotosm/gh-workflows/.github/workflows/some_workflow.yml@main\n\ndo-something-else:\n  uses: hotosm/gh-workflows/.github/workflows/some_workflow2.yml@main\n  needs: [do-something]\n  with:\n    # Run workflow with a variable output from previous workflow\n    some_variable: ${{ needs.do-something.outputs.var1 }}\n</code></pre>"},{"location":"intro/#cache","title":"Cache","text":"<p>Caching is used for persisting data across workflow multiple runs.</p> <p>Example flow:</p> <ol> <li>Workflow pulls a container image to run a task.</li> <li>This workflow runs the first time on a pull request.</li> <li>The container image is cached.</li> <li>The developer makes some edits and pushes new commits to the PR.</li> <li>The cache is hit for the PR, so the container image does not download    again.</li> </ol> <p>As you can see, this is a useful efficiency gain for workflows running many times consecutively.</p> <p>Caches are scoped to a branch, so the cache for <code>main</code> is not available within a PR.</p>"},{"location":"intro/#artifacts","title":"Artifacts","text":"<p>Artifacts are used for persisting files within a single workflow run.</p> <p>Example flow:</p> <ol> <li>Workflow 1 creates file</li> <li>Uploads as artifact</li> <li>Workflow 2 downloads artifacts</li> <li>File can be used in workflow 2.</li> </ol> <p>Artifact also make file outputs available via the Github CLI (e.g. for making releases that the user can download).</p>"},{"location":"just/","title":"Just Runner","text":"<p>Used to run Just commands configured via Justfile in the repo, for simple CI/CD workflows.</p>"},{"location":"just/#inputs","title":"Inputs","text":"INPUT TYPE REQUIRED DEFAULT DESCRIPTION command string true The Just command to run (defined in Justfile). environment string true The Github environment to use for variables. example_env_file_path string false <code>\".env.example\"</code> Path to example dotenv file to substitute variables for."},{"location":"just/#outputs","title":"Outputs","text":"<p>No outputs.</p>"},{"location":"just/#secrets","title":"Secrets","text":"<p>No secrets.</p>"},{"location":"just/#example-usage","title":"Example Usage","text":""},{"location":"mkdocs_build/","title":"MKDocs Build","text":"<p>Build docs using Python mkdocs.</p> <p>You need to have:</p> <ul> <li><code>docs</code> directory at root level.</li> <li>mkdocs.yml config file.</li> </ul>"},{"location":"mkdocs_build/#inputs","title":"Inputs","text":"INPUT TYPE REQUIRED DEFAULT DESCRIPTION doxygen string false Include doxygen output uploaded to <code>artifact</code> key. image string false <code>\"ghcr.io/hotosm/gh-workflows/mkdocs:main\"</code> Override the image to build mkdocs. include_artifacts string false Include all uploaded artifacts from the workflow. keep_extra_files boolean false <code>false</code> Only update modified files. Default false, to clean repo before push. openapi string false Include openapi output uploaded to <code>artifact</code> key."},{"location":"mkdocs_build/#outputs","title":"Outputs","text":"<p>No outputs.</p>"},{"location":"mkdocs_build/#secrets","title":"Secrets","text":"<p>No secrets.</p>"},{"location":"mkdocs_build/#example-usage","title":"Example Usage","text":"<p>Simple publish:</p> <pre><code>name: Publish Docs\n\non:\n  push:\n\njobs:\n  publish_docs:\n    uses: hotosm/gh-workflows/.github/workflows/mkdocs_build.yml@main\n</code></pre> <p>Publish with Doxygen &amp; OpenAPI YAML:</p> <pre><code>name: Publish Docs\n\non:\n  push:\n    paths:\n      - docs/**\n      - src/**\n      - mkdocs.yml\n    branches: [development]\n  # Allow manual trigger (workflow_dispatch)\n  workflow_dispatch:\n\njobs:\n  build_doxygen:\n    uses: hotosm/gh-workflows/.github/workflows/doxygen_build.yml@main\n    with:\n      output_path: docs/apidocs\n\n  build_openapi_json:\n    uses: hotosm/gh-workflows/.github/workflows/openapi_build.yml@main\n    with:\n      image: ghcr.io/${{ github.repository }}/backend:ci-${{ github.ref_name }}\n      example_env_file_path: \".env.example\"\n      output_path: docs/openapi.json\n\n  publish_docs:\n    uses: hotosm/gh-workflows/.github/workflows/mkdocs_build.yml@main\n    needs:\n      - build_doxygen\n      - build_openapi_json\n    with:\n      image: ghcr.io/${{ github.repository }}/backend:ci-${{ github.ref_name }}\n      doxygen: true\n      openapi: true\n</code></pre>"},{"location":"npm_publish/","title":"NPM Publish","text":"<p>Publish a package to NPMJS using PNPM.</p>"},{"location":"npm_publish/#inputs","title":"Inputs","text":"<p>No inputs.</p>"},{"location":"npm_publish/#outputs","title":"Outputs","text":"<p>No outputs.</p>"},{"location":"npm_publish/#secrets","title":"Secrets","text":"SECRET REQUIRED DESCRIPTION NPM_TOKEN true The npmjs.org API token for your project."},{"location":"npm_publish/#example-usage","title":"Example Usage","text":"<pre><code>name: Publish to npmjs.org\n\non:\n  release:\n    types: [published]\n  # Allow manual trigger (workflow_dispatch)\n  workflow_dispatch:\n\njobs:\n  publish_to_npmjs:\n    uses: hotosm/gh-workflows/.github/workflows/pnpm_publish.yml@main\n    secrets:\n      NPM_TOKEN: ${{ secrets.NPM_TOKEN }}\n</code></pre>"},{"location":"openapi_build/","title":"OpenAPI Build","text":"<p>Build OpenAPI YAML for use in Swagger or ReDoc documentation sites.</p>"},{"location":"openapi_build/#inputs","title":"Inputs","text":"INPUT TYPE REQUIRED DEFAULT DESCRIPTION container_user string false <code>\"root\"</code> The user to run the container as. Defaults to root. example_env_file_path string true FastAPI must start with an environment set. Path to a .env with dummy vars. image string true The image to build to OpenAPI JSON (dependencies included, i.e. FastAPI.). output_file_write_path string false <code>\"docs/openapi.json\"</code> The path to write the OpenAPI JSON file to. Defaults to <code>docs/openapi.json</code>. output_path string false If specified, the output dir is uploaded to the <code>artifact</code> key. py_backend_app_context string false <code>\"app.main\"</code> The context to import the FastAPI app from. Defaults to <code>app.main</code>. py_backend_app_name string false <code>\"api\"</code> The name of the FastAPI app. Defaults to <code>api</code>."},{"location":"openapi_build/#outputs","title":"Outputs","text":"<p>No outputs.</p>"},{"location":"openapi_build/#secrets","title":"Secrets","text":"<p>No secrets.</p>"},{"location":"openapi_build/#example-usage","title":"Example Usage","text":"<pre><code>name: \ud83d\udcd6 Publish Docs\n\non:\n  push:\n    paths:\n      - docs/**\n      - src/**\n      - mkdocs.yml\n    branches: [development]\n  # Allow manual trigger (workflow_dispatch)\n  workflow_dispatch:\n\njobs:\n  build_openapi_json:\n    uses: hotosm/gh-workflows/.github/workflows/openapi_build.yml@1.6.0\n    with:\n      image: ghcr.io/${{ github.repository }}/backend:ci-${{ github.ref_name }}\n      example_env_file_path: \".env.example\"\n      output_path: docs/openapi.json\n\n  publish_docs:\n    uses: hotosm/gh-workflows/.github/workflows/mkdocs_build.yml@1.6.0\n    needs:\n      - build_openapi_json\n    with:\n      image: ghcr.io/${{ github.repository }}/backend:ci-${{ github.ref_name }}\n      openapi: true\n</code></pre>"},{"location":"pnpm_build/","title":"Stories Build","text":"<p>This workflow is used to build stories for UI components.</p> <p>The workflow uses PNPM to install dependnecies and run the npm command that builds the stories dist.</p>"},{"location":"pnpm_build/#inputs","title":"Inputs","text":"INPUT TYPE REQUIRED DEFAULT DESCRIPTION command string true The pnpm command to run in package.json. github_pages boolean false <code>false</code> Upload in format specific for Github Pages <code>actions/deploy-pages</code>. output_path string false The output path is uploaded to a key named <code>artifact</code>. working_dir string false <code>\".\"</code> The directory containing the package.json file."},{"location":"pnpm_build/#outputs","title":"Outputs","text":"OUTPUT VALUE DESCRIPTION artifact_name <code>\"build\"</code> The artifact name (default: <code>artifact</code>)."},{"location":"pnpm_build/#secrets","title":"Secrets","text":"<p>No secrets.</p>"},{"location":"pnpm_build/#example-usage","title":"Example Usage","text":"<pre><code>name: \ud83d\udcd6 Publish Docs\n\non:\n  push:\n    paths:\n      - docs/**\n      - src/**\n      - mkdocs.yml\n    branches: [main]\n  # Allow manual trigger (workflow_dispatch)\n  workflow_dispatch:\n\njobs:\n  build_stories:\n    uses: hotosm/gh-workflows/.github/workflows/pnpm_build.yml@1.6.0\n    with:\n      npm_cmd: build:docs\n      output_path: docs/stories\n\n  publish_docs:\n    uses: hotosm/gh-workflows/.github/workflows/mkdocs_build.yml@1.6.0\n    needs: [build_stories]\n    with:\n      stories: true\n</code></pre>"},{"location":"py_app_version/","title":"Extract Python App Version","text":"<p>Output the version of a Python application, using the version.py file.</p>"},{"location":"py_app_version/#inputs","title":"Inputs","text":"INPUT TYPE REQUIRED DEFAULT DESCRIPTION package_name string true The package_name that version.py sits under."},{"location":"py_app_version/#outputs","title":"Outputs","text":"OUTPUT VALUE DESCRIPTION app_version <code>\"${{ jobs.extract-app-version.outputs.app_version }}\"</code> Python app version."},{"location":"py_app_version/#secrets","title":"Secrets","text":"<p>No secrets.</p>"},{"location":"py_app_version/#example-usage","title":"Example Usage","text":"<pre><code>jobs:\n  extract-vars:\n    uses: hotosm/gh-workflows/.github/workflows/py_app_version.yml@main\n    with:\n      package_name: osm_fieldwork\n\n  backend-ci-build:\n    uses: hotosm/gh-workflows/.github/workflows/image_build.yml@main\n    needs: [extract-vars]\n    with:\n      context: .\n      build_target: ci\n      image_tags: |\n        \"ghcr.io/hotosm/osm-fieldwork:ci-${{ github.ref_name }}\"\n      extra_build_args: |\n        APP_VERSION=${{ needs.extract-vars.outputs.app_version }}\n</code></pre>"},{"location":"pypi_publish/","title":"PyPi Publish","text":"<p>Publish a package to PyPi using PDM.</p> <p>You must use PDM for your package management for this workflow to function.</p>"},{"location":"pypi_publish/#inputs","title":"Inputs","text":"<p>No inputs.</p>"},{"location":"pypi_publish/#outputs","title":"Outputs","text":"<p>No outputs.</p>"},{"location":"pypi_publish/#secrets","title":"Secrets","text":"SECRET REQUIRED DESCRIPTION PYPI_TOKEN true The PyPi.org API token for your project."},{"location":"pypi_publish/#example-usage","title":"Example Usage","text":"<pre><code>name: Publish to PyPi.org\n\non:\n  release:\n    types: [published]\n  # Allow manual trigger (workflow_dispatch)\n  workflow_dispatch:\n\njobs:\n  publish_to_pypi:\n    uses: hotosm/gh-workflows/.github/workflows/pypi_publish.yml@main\n    secrets:\n      PYPI_TOKEN: ${{ secrets.PYPI_TOKEN }}\n</code></pre>"},{"location":"remote_deploy_compose/","title":"Remote Deploy (Docker Compose)","text":"<p>Deploy to a remote server using docker compose and SSH keys.</p> <p>This workflow uses the DOCKER_HOST variable underneath during deploy.</p>"},{"location":"remote_deploy_compose/#prerequisites","title":"Prerequisites","text":"<ul> <li> <p>There must be a <code>.env.example</code> file in the root of your repo.</p> <ul> <li>This file describes all possible environment variables,   with examples.</li> <li>The variables in this file are substituted to produce the   <code>.env</code> file used during deploy.</li> </ul> <pre><code>SECRET_KEY=${SECRET_KEY:-somesuperdupersecretkeyfortesting}\nALLOWED_HOSTS=${ALLOWED_HOSTS:-[\"*\"]}\nDB_NAME=${DB_NAME:-\"\"}\nDB_USER=${DB_USER:-\"\"}\nDB_PASSWORD=${DB_PASSWORD:-\"\"}\nDB_HOST=${DB_HOST:-\"\"}\nDB_PORT=${DB_PORT:-5432}\n</code></pre> </li> </ul> <ul> <li> <p>You must have variables configured for your Github environment:</p> <ul> <li>SSH_HOST (var) - the domain name or IP address for deploy.</li> <li>SSH_USER (var) - the user the SSH keypair was generated for.</li> <li>SSH_PRIVATE_KEY (secret) - the private key of the keypair.</li> </ul> </li> </ul> <ul> <li> <p>When calling the workflow:</p> <ul> <li>You need to pass the <code>environment</code> variable to   extract the variables from your deployment environment.</li> <li>This can be <code>environment: ${{ github.ref_name }}</code> to use the git branch name.</li> <li>Important: the secrets param must be: <code>secrets: inherit</code>.</li> </ul> </li> </ul>"},{"location":"remote_deploy_compose/#inputs","title":"Inputs","text":"INPUT TYPE REQUIRED DEFAULT DESCRIPTION docker_compose_file string true Path to docker compose file to deploy. environment string false The Github environment to get variables from. Default repository vars. example_env_file_path string false <code>\".env.example\"</code> Path to example dotenv file to substitute variables for."},{"location":"remote_deploy_compose/#outputs","title":"Outputs","text":"<p>No outputs.</p>"},{"location":"remote_deploy_compose/#secrets","title":"Secrets","text":"<p>No secrets.</p>"},{"location":"remote_deploy_compose/#example-usage","title":"Example Usage","text":"<pre><code>deploy-containers:\n  needs:\n    - smoke-test-backend\n    - smoke-test-frontend\n  uses: hotosm/gh-workflows/.github/workflows/remote_deploy_compose.yml@main\n  with:\n    environment: ${{ github.ref_name }}\n    docker_compose_file: \"compose.${{ github.ref_name }}.yml\"\n  secrets: inherit\n</code></pre>"},{"location":"remote_deploy_just/","title":"Remote Deploy (Just)","text":"<p>Deploy to a remote server using Justfile command and SSH keys.</p> <p>This workflow uses the DOCKER_HOST variable underneath during deploy.</p> <p>It's an alternative to <code>remote_deploy_compose</code> to allow each project to include project-specific config for their deploy.</p>"},{"location":"remote_deploy_just/#prerequisites","title":"Prerequisites","text":"<ul> <li> <p>You must have variables configured for your Github environment:</p> <ul> <li>SSH_HOST (var) - the domain name or IP address for deploy.</li> <li>SSH_USER (var) - the user the SSH keypair was generated for.</li> <li>SSH_PRIVATE_KEY (secret) - the private key of the keypair.</li> </ul> </li> </ul> <ul> <li> <p>When calling the workflow:</p> <ul> <li>You need to pass the <code>environment</code> variable to   extract the variables from your deployment environment.</li> <li>This can be <code>environment: ${{ github.ref_name }}</code> to use the git branch name.</li> <li>Important: the secrets param must be: <code>secrets: inherit</code>.</li> </ul> </li> </ul>"},{"location":"remote_deploy_just/#inputs","title":"Inputs","text":"INPUT TYPE REQUIRED DEFAULT DESCRIPTION command string true The Just command to run (defined in Justfile). environment string false The Github environment to get variables from. Default repository vars. example_env_file_path string false <code>\".env.example\"</code> Path to example dotenv file to substitute variables for."},{"location":"remote_deploy_just/#outputs","title":"Outputs","text":"<p>No outputs.</p>"},{"location":"remote_deploy_just/#secrets","title":"Secrets","text":"<p>No secrets.</p>"},{"location":"remote_deploy_just/#example-usage","title":"Example Usage","text":"<pre><code>deploy-containers:\n  needs:\n    - smoke-test-backend\n    - smoke-test-frontend\n  uses: hotosm/gh-workflows/.github/workflows/remote_deploy_just.yml@main\n  with:\n    environment: ${{ github.ref_name }}\n    command: start prod\n  secrets: inherit\n</code></pre>"},{"location":"test_compose/","title":"Test via Docker Compose","text":"<p>Run tests inside a container, as part of a docker compose stack.</p> <p>This is useful for tests when the tests require, e.g. an underlying database, or any additional services.</p> <p>If you are not sure on what test to use, this is likely the one! Most tests require additional services like a database.</p>"},{"location":"test_compose/#prerequisites","title":"Prerequisites","text":"<ul> <li> <p>The tests inside the container, by two possible options:</p> <ul> <li>Copied into your container build under WORKDIR.</li> <li>Mounted within the compose.yaml file under WORKDIR.</li> </ul> </li> </ul> <ul> <li>The testing tool must be installed for the dockerfile USER.</li> </ul> <ul> <li> <p>The service in the compose.yaml must have a TAG_OVERRIDE.</p> <pre><code>services:\n  api:\n    image: \"ghcr.io/hotosm/field-tm/backend:${TAG_OVERRIDE:-debug}\"\n</code></pre> <p>This allows the workflow to inject the tag of the image built for a PR, or during deployment.</p> </li> </ul> <ul> <li> <p>There should be a <code>.env.example</code> file in the root of your repo,   if you require any environment variables to run your service.</p> <ul> <li>This file describes all possible environment variables,   with examples.</li> <li>The variables in this file are substituted to produce the   <code>.env</code> file from Github environment variables.</li> </ul> <pre><code>SECRET_KEY=${SECRET_KEY:-somesuperdupersecretkeyfortesting}\nALLOWED_HOSTS=${ALLOWED_HOSTS:-[\"*\"]}\nDB_NAME=${DB_NAME:-\"\"}\nDB_USER=${DB_USER:-\"\"}\nDB_PASSWORD=${DB_PASSWORD:-\"\"}\nDB_HOST=${DB_HOST:-\"\"}\nDB_PORT=${DB_PORT:-5432}\n</code></pre> <p>Note: the syntax above sets the default tag to 'debug', unless the TAG_OVERRIDE variable is present in the environment (this workflow sets the variable).</p> </li> </ul> <ul> <li> <p>Finally, the environment variables you wish to substitute   must be present as environment variables or secrets in your   Github repository settings.</p> <ul> <li>The environment name default is <code>test</code>.</li> <li>It is possible to override which environment to use by setting   workflow input <code>environment</code>.</li> <li>Important: to ensure that secrets are passed to the workflow,   you must add <code>secrets: inherit</code> (see examples below).</li> </ul> </li> </ul>"},{"location":"test_compose/#faq","title":"FAQ","text":""},{"location":"test_compose/#environment-variables-are-not-injecting","title":"Environment variables are not injecting","text":"<p>There may be an issue with your <code>.env.example</code>.</p> <p>A template such as the example above is required to generate a <code>.env</code> file from <code>.env.example</code>.</p> <p>In this example:</p> <pre><code>ALLOWED_HOSTS=${ALLOWED_HOSTS:-[\"*\"]}\n</code></pre> <p>The variable <code>ALLOWED_HOSTS</code> will be substituted to:</p> <pre><code># If ALLOWED_HOSTS is present in your environment\nALLOWED_HOSTS=[\"https://some.domain.org\"]\n# [\"https://some.domain.org\"] is the value in your Github environment\n\n# If no variable is set in your environment, the default is used.\n# This is the value after the :- above (in bash substitution syntax).\nALLOWED_HOSTS=[\"*\"]\n</code></pre>"},{"location":"test_compose/#hostnames-are-not-resolving","title":"Hostnames are not resolving","text":"<p>For example, your app requires the database, but the database service name is not available.</p> <p>An example in Django would look like:</p> <pre><code>django.db.utils.OperationalError: could not translate\nhost name \"db\" to address: Temporary failure in name resolution\n</code></pre> <p>This may be because the database has not initialised completely, prior to running the command.</p> <p>To solve this, update your docker compose file to use <code>depends_on</code>, under your app service:</p> <pre><code>services:\n  app:\n    ...\n    depends_on:\n      db:\n        condition: service_healthy\n</code></pre> <p>To facilitate this, it is good practice to add a healthcheck to containers. We should use a healthcheck that determines the database has started and is healthy.</p> <p>If building a custom Dockerfile, you can add a HEATHCHECK directive.</p> <p>But many will use a standard unmodified database image, so the heathcheck is added in docker compose:</p> <pre><code>services:\n  db:\n    ...\n    healthcheck:\n      test: pg_isready -U ${DB_USER:-postgres} -d ${DB_NAME:-postgres}\n      start_period: 5s\n      interval: 10s\n      timeout: 5s\n      retries: 3\n</code></pre>"},{"location":"test_compose/#coverage-files-are-overwritten","title":"Coverage files are overwritten","text":"<ul> <li>If you run this workflow, then the mkdocs_build workflow directly   afterwards, the coverage files may get overwritten.</li> <li>To solve this, add the <code>keep_extra_files</code> variable to the mkdocs_build   workflow to retain the <code>coverage.html</code> and <code>coverage.svg</code> badge.</li> </ul>"},{"location":"test_compose/#inputs","title":"Inputs","text":"INPUT TYPE REQUIRED DEFAULT DESCRIPTION build_context string false <code>\".\"</code> Root directory to start the build from. build_dockerfile string false <code>\"Dockerfile\"</code> Name of dockerfile, relative to context dir. build_target string false <code>\"ci\"</code> The target to built to (default to ci stage). cache_extra_imgs string false Space separated list of images to cache on each run (e.g. to avoid rate limiting). cache_image boolean false <code>true</code> Cache the built image, for the next run. Default true. compose_command string false The command to run for the container. Default to built-in image command. compose_file string false <code>\"docker-compose.yml\"</code> The docker compose file used to run the test. compose_service string true The docker compose service to run the test against. coverage boolean false <code>false</code> Generate a coverage HTML report (requires coverage.py installed). environment string false <code>\"test\"</code> The environment to use for testing. example_env_file_path string false <code>\".env.example\"</code> Path to example dotenv file to substitute variables for. extra_build_args string false Space separated list of build args to use for the image. image_name string false The image root name to build, without tag. E.g. 'ghcr.io/[dollar]{{ github.repository }}' playwright boolean false <code>false</code> Upload the Playwright trace files as an artifact for debugging. pre_command string false A initialisation command to run prior to the docker compose command. tag_override string false An override for the build image tag. Must include tests and have test software installed"},{"location":"test_compose/#outputs","title":"Outputs","text":"<p>No outputs.</p>"},{"location":"test_compose/#secrets","title":"Secrets","text":"<p>No secrets.</p>"},{"location":"test_compose/#example-usage","title":"Example Usage","text":"<p>Running during PR:</p> <pre><code>name: PR Test Backend\n\non:\n  pull_request:\n    branches:\n      - main\n      - staging\n      - development\n    # Workflow is triggered only if src/backend changes\n    paths:\n      - src/backend/**\n  # Allow manual trigger (workflow_dispatch)\n  workflow_dispatch:\n\njobs:\n  pytest:\n    uses: hotosm/gh-workflows/.github/workflows/test_compose.yml@main\n    with:\n      image_name: ghcr.io/${{ github.repository }}/backend\n      build_context: src/backend\n      extra_build_args: |\n        APP_VERSION=${{ github.ref_name }}\n        COMMIT_REF=${{ github.sha }}\n      docker_compose_service: api\n      docker_compose_command: wait-for-it fmtm-db:5432 --strict -- wait-for-it central:8383 --strict --timeout=30 -- pytest\n      cache_extra_imgs: |\n        \"docker.io/postgis/postgis:${{ vars.POSTGIS_TAG }}\"\n        \"docker.io/minio/minio:${{ vars.MINIO_TAG }}\"\n    secrets: inherit\n</code></pre> <p>Running prior to deployment:</p> <pre><code>name: Build and Deploy\n\non:\n  # Push includes PR merge\n  push:\n    branches:\n      - main\n      - staging\n      - development\n    paths:\n      # Workflow is triggered only if src changes\n      - src/**\n  # Allow manual trigger\n  workflow_dispatch:\n\njobs:\n  pytest:\n    uses: hotosm/gh-workflows/.github/workflows/test_compose.yml@main\n    with:\n      image_name: ghcr.io/${{ github.repository }}/backend\n      build_context: src/backend\n      extra_build_args: |\n        APP_VERSION=${{ github.ref_name }}\n        COMMIT_REF=${{ github.sha }}\n      docker_compose_service: api\n      docker_compose_command: wait-for-it fmtm-db:5432 --strict -- wait-for-it central:8383 --strict --timeout=30 -- pytest\n      tag_override: ci-${{ github.ref_name }}\n    secrets: inherit\n## Continue to deploy...\n</code></pre>"},{"location":"test_pnpm/","title":"PyTest (via Docker Compose)","text":"<p>Set up the PNPM environment and run tests using <code>pnpm run test</code>.</p>"},{"location":"test_pnpm/#inputs","title":"Inputs","text":"INPUT TYPE REQUIRED DEFAULT DESCRIPTION container_config string false <code>\"{\\\"image\\\": null}\"</code> Run with a custom docker image, instead of directly on Ubuntu machine. run_command string false <code>\"test\"</code> The command to run: <code>pnpm run xxx</code>. working_dir string false <code>\".\"</code> The directory containing the package.json file."},{"location":"test_pnpm/#outputs","title":"Outputs","text":"<p>No outputs.</p>"},{"location":"test_pnpm/#secrets","title":"Secrets","text":"<p>No secrets.</p>"},{"location":"test_pnpm/#example-usage","title":"Example Usage","text":"<p>Run commands directly on <code>ubuntu-latest</code> machine.</p> <pre><code>jobs:\n  frontend-tests:\n    uses: hotosm/gh-workflows/.github/workflows/test_pnpm.yml@main\n    with:\n      working_dir: src/frontend\n</code></pre> <p>Run using a custom container. For example Playwright:</p> <pre><code>jobs:\n  frontend-tests:\n    uses: hotosm/gh-workflows/.github/workflows/test_pnpm.yml@main\n    with:\n      container_config: '{\"image\": \"mcr.microsoft.com/playwright:v1.43.0\"}'\n      working_dir: src/frontend\n      run_command: \"test:e2e\"\n</code></pre>"},{"location":"test_pytest/","title":"PyTest (without Docker Compose)","text":"<p>Run pytest for your application, inside a container.</p>"},{"location":"test_pytest/#prerequisites","title":"Prerequisites","text":"<ul> <li>The tests must be included in the image (via Dockerfile).</li> </ul> <ul> <li>PyTest must be installed for the dockerfile USER.</li> </ul> <p>Note: this workflow also injects dotenv vars present in your Github environment called <code>test</code> (or set by <code>inputs.environment</code>). See the test_compose docs for more details.</p>"},{"location":"test_pytest/#inputs","title":"Inputs","text":"INPUT TYPE REQUIRED DEFAULT DESCRIPTION build_context string false <code>\".\"</code> Root directory to start the build from. build_dockerfile string false <code>\"Dockerfile\"</code> Name of dockerfile, relative to context dir. build_target string false <code>\"ci\"</code> The target to built to (default to ci stage). cache_image boolean false <code>true</code> Cache the built image, for the next run. Default true. environment string false <code>\"test\"</code> The environment to use for testing. example_env_file_path string false <code>\".env.example\"</code> Path to example dotenv file to substitute variables for. extra_build_args string false Space separated list of build args to use for the image. image_name string true The image root name, without tag. E.g. 'ghcr.io/[dollar]{{ github.repository }}' tag_override string false An override for the build image tag. Must include tests and have PyTest installed"},{"location":"test_pytest/#outputs","title":"Outputs","text":"<p>No outputs.</p>"},{"location":"test_pytest/#secrets","title":"Secrets","text":"<p>No secrets.</p>"},{"location":"test_pytest/#example-usage","title":"Example Usage","text":"<p>Running on push and PR:</p> <pre><code>name: pytest\n\non:\n  push:\n    branches: [main]\n  # Run tests on PR, prior to merge to main &amp; development\n  pull_request:\n    branches: [main]\n  # Allow manual trigger (workflow_dispatch)\n  workflow_dispatch:\n\njobs:\n  pytest:\n    uses: hotosm/gh-workflows/.github/workflows/test_pytest.yml@main\n    with:\n      image_name: ghcr.io/${{ github.repository }}\n      extra_build_args: |\n        COMMIT_REF=${{ github.sha }}\n      tag_override: ${{ github.event_name == 'push' &amp;&amp; 'ci' || '' }}\n</code></pre> <p>This includes a tag_override, so that in a pull_request event the image is tagged with the PR number, but during a push event the image is tagged as <code>ci</code> (to not confuse it with releases).</p>"},{"location":"wiki/","title":"Wiki Build","text":"<p>Copy a gh-pages <code>docs</code> directory to Github Wiki.</p>"},{"location":"wiki/#inputs","title":"Inputs","text":"INPUT TYPE REQUIRED DEFAULT DESCRIPTION homepage_path string false <code>\"Home.md\"</code> The file to rename to <code>Home.md</code> for the root Wiki page, relative from <code>docs</code> dir."},{"location":"wiki/#outputs","title":"Outputs","text":"<p>No outputs.</p>"},{"location":"wiki/#secrets","title":"Secrets","text":"<p>No secrets.</p>"}]}